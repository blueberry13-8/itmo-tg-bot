{
  "program": "ai",
  "pdf": "data\\plans\\ai.pdf",
  "text": "Вопросы для подготовки к вступительному\nтестированию: техническая часть.\nПрограмма “Искусственный интеллект” и\n“Управление AI-продуктом” ИТМО\nСписок тем, входящих в блок Hard Skills в рамках вступительного\nонлайн-тестирования:\n1. Программирование на языке Python.\n2. Алгоритмы и структуры данных.\n3. Теория множеств. Теория графов.\n4. Теория вероятностей и математическая статистика.\n5. Базы данных. SQL и NoSQL.\n6. Основные концепции Big Data.\n7. Основы машинного обучения.\n8. Нейронные сети.\n9. Основы компьютерного зрения (CV).\n10. Основы обработки естественного языка (NLP).\n11. Инструменты промышленной разработки ПО.\n1. Программирование на Python\nПодтемы\n● Списковые включения и генераторы\n● Декораторы и контекст-менеджеры\n● Типизация и статическая проверка\n● Асинхронность (asyncio)\n● Файлы и форматы данных\n● Тестирование (pytest)\n● Packaging и окружения\n● Профилировка и оптимизация\nПримерные вопросы\n● Чем list comprehension отличается от обычного цикла for?\n● Когда стоит писать собственный контекст‑менеджер через @contextmanager?\n● Поясните разницу между typing.List[int] и list[int] в Python 3.9+.\n● В чём преимущества asyncio по сравнению с потоками при I/O‑задачах?\n● Что происходит, когда функция достигает выражения yield?\n● Как организовать parametrized tests в pytest?\nРекомендуемые материалы\n● Официальная документация Python (рус.)\n● Stepik курс «Поколение Python»\n● LearnPython.ru – интерактивный тренажёр\n2. Алгоритмы и структуры данных\nПодтемы\n● Анализ сложности, Big-O и амортизированная оценка\n● Сортировки O(n log n) и ниже: быстрая, слиянием, кучей, radix\n● Рекурсия и динамическое программирование: мемоизация, оптимальный\nразрез\n● Диапазонные структуры: дерево отрезков, дерево Фенвика, sparse table\n● Пространственные индексы k-NN: KD-tree, Ball-tree, HNSW\n● Система непересекающихся множеств (DSU) и эвристики rank/ path\ncompression\n● Поиск кратчайших путей: Дейкстра, A*, Bellman–Ford\n● Алгоритмы MST и базовых графов: Краскал, Прим, BFS/DFS, топологическая\nсортировка\n● Строковые алгоритмы: префикс-функция (КМП), Z-функция, суффикс-массив и\nLCP\n● Хеш-структуры и коллизии: хеш-таблица, bloom-filter, perfect hashing\n● Рекурсия и динамическое программирование\nПримерные вопросы\n● Почему быстрая сортировка имеет среднюю сложность O(n log n), но худшую\nO(n²)?\n● Докажите, что алгоритм динамического программирования для задачи о\nрюкзаке работает за O(nW).\n● Чем дерево отрезков удобнее массива префиксных сумм для диапазонных\nобновлений?\n● Опишите операции Make‑Set, Find, Union для DSU и их сложность с\nэвристиками.\n● Как работает очередь с приоритетом в реализации Дейкстры на C++ STL?\n● Для чего нужна префикс‑функция в алгоритме КМП?\nРекомендуемые материалы\n● e-maxx.ru – Алгоритмы на русском\n● Stepik «Алгоритмы: теория и практика. Методы»\n● Лекции МФТИ «Алгоритмы и структуры данных» (YouTube)\n3. Теория множеств и графов\nПодтемы\n● Основы множеств и операций ∪ ∩ ; мощности и принцип\nвключения-исключения\n● Перечислительная комбинаторика: перестановки, размещения, сочетания,\nбиномиальные коэффициенты\n● Планарные графы: критерий Куратовского, формула Эйлера,\nпредел |E| ≤ 3|V| − 6\n● Обходы и связность: BFS/DFS, компоненты, топологическая сортировка\n● Минимальные остовные деревья: свойства cut & cycle, алгоритмы Краскала и\nПрима\n● Теория потоков: max-flow ↔ min-cut, алгоритмы Эдмондса–Карпа и Диница\n● Паросочетания в двудольных графах: теорема Холла, алгоритм\nКуна/Хопкрофта-Карпа\n● Эйлеровы и гамильтоновы циклы: критерии существования, алгоритм Флёри /\nтеорема Дирака\n● Маршруты Эйлера и Гамильтона\nПримерные вопросы\n● Сколько различных функций можно задать на множестве из n элементов?\n● Сформулируйте и докажите формулу Эйлера для связного плоского графа.\n● Когда алгоритм Краскала предпочтительнее алгоритма Прима?\n● Почему алгоритм Эдмондса–Карпа имеет сложность O(VE²)?\n● Докажите теорему Холла для двудольных графов.\n● Дайте критерий существования эйлерова цикла в неориентированном графе.\nРекомендуемые материалы\n● Лекции И. Куликова «Теория графов» (YouTube)\n● Stepik курс «Теория графов»\n● e-maxx.ru – раздел «Графы»\n4. Теория вероятностей и математическая статистика\nПодтемы\n● Ожидание и дисперсия случайных величин\n● Закон больших чисел и ЦПТ\n● Оценка параметров: ММП и метод моментов\n● Статистические критерии (χ², t‑тест)\n● Неравенства Маркова и Чебышёва\n● Методы Монте‑Карло\n● Байесовское обновление при диагностических тестах (деревья вероятностей).\n● Условные вероятности. Определение условной вероятности, формула полной\nвероятности, формула Байеса. Независимость событий на вероятностном\nпространстве. Попарная независимость и независимость в совокуп- ности.\n● Схема Бернулли. Формула Бернулли. Формула Пуассона. Формулы\nМуавра-Лапласа и их применение. По- линомиальная схема\n● Случайные величины как измеримые функции. Функция распределения.\nФункция плотности. Независимость случайных величин. Случайные векторы.\nФункции от случайной величины.\n● Математическое ожидание в дискретном и абсолютно непрерывном случае,\nдисперсия, ковариация и корре- ляция. Их основные свойства. Дисперсия\nсуммы независимых случайных величин. Математическое ожидание и матрица\nковариаций случайного вектора. Симметричность и неотрицательная\nопределенность матрицы ко- вариаций. Математическое ожидание случайной\nвеличины в общем виде. Условное математическое ожидание. Регрессия.\nДругие числовые характеристики случайных величин. Моменты старших\nпорядков.\n● Распределения. Стандартные дискретные и непрерывные распределения, их\nматематические ожидания, дис- персии и свойства: биномиальное;\nравномерное; нормальное и многомерное нормальное; пуассоновское; показа-\nтельное; геометрическое; отрицательно-биномиальное; распределение\nПаскаля; гипергеометрическое; распре- деление Гнеденко-Вейбулла;\nгамма-распределение.\nПримерные вопросы\n● Выведите формулу дисперсии через математическое ожидание.\n● Сформулируйте сильный закон больших чисел.\n● Чем отличается несмещённая оценка от состоятельной?\n● При каких предпосылках применяется t‑тест Стьюдента?\n● Докажите неравенство Чебышёва.\n● Как оценить π методом Монте‑Карло?\nРекомендуемые материалы\n● Лекции К. Воронцова «Теория вероятностей» (pdf)\n● Stepik курс «Теория вероятностей»\n● Учебник Б. В. Гнеденко «Курс теории вероятностей» (эл. версия)\n5. Базы данных. SQL и NoSQL\nПодтемы\n● Индексы и хранение: B-tree, Hash, GIN/GiST/BRIN, bitmap, партиционирование\n● Запросы SQL: CTE, оконные функции, агрегация, UPSERT, субзапросы, EXPLAIN\n● Нормализация ↔ денормализация: 1NF–BCNF, схемы звезда/снежинка,\nшардирование\n● Транзакции и изоляция: MVCC, Read Committed, Repeatable Read, Serializable\n● JSON/JSONB и semi-structured: операторы ->, @>, индексация, full-text-search\n● ORM‑фреймворки (SQLAlchemy, Django ORM)\n● NoSQL модели и CAP/BASE: документные, key-value, графовые, колоннарные\n● Репликация, резервное копирование и тюнинг производительности\n● ACID vs BASE в распределённых БД\nПримерные вопросы\n● Как B‑tree индекс ускоряет запросы с оператором BETWEEN?\n● Опишите различие уровней изоляции Read Committed и Serializable.\n● Покажите пример использования оконной функции ROW_NUMBER().\n● Какие преимущества JSONB перед JSON в PostgreSQL?\n● Что такое lazy loading в ORM и когда оно вредно?\n● Почему BASE‑подход часто выбирают для NoSQL систем?\nРекомендуемые материалы\n● Документация PostgreSQL (рус.)\n● Stepik курс «SQL для анализа данных»\n● Хабр‑коллекция «Базы данных»\n6. Основные концепции Big Data\nПодтемы\n● Парадигма Map-Reduce и эволюция от Hadoop MR к Spark\n● Apache Spark: RDD, DataFrame/Dataset API, Catalyst, Tungsten, lazy-evaluation\n● Управление кластерами: YARN, Mesos, Stand-alone, Kubernetes Scheduler\n● Kafka / Pulsar и потоковая обработка: Exactly-once, Kafka Streams, Spark\nStructured Streaming\n● Хранилища данных 3-го поколения: Data Lake + Delta Lake (ACID-слои,\ntime-travel, schema evolution)\n● Data Vault 2.0: моделирование hub-link-satellite, PIT-таблицы, бизнес-ключ vs\nsurrogate key\n● Partitioning & Bucketing: стратегии по диапазону, хэшу, времени; динамические\nпартиции\n● HDFS репликация и fault‑tolerance\n● Колоночно-ориентированные форматы Hydra и компрессия: Parquet, ORC,\nZSTD, Snappy, predicate pushdown\n● Мониторинг и fault-tolerance: speculative execution, checkpointing, lineage и\nDAG-визуализация\nПримерные вопросы\n● Чем DataFrame в Spark отличается от RDD с точки зрения оптимизации?\n● Опишите архитектуру YARN: ResourceManager и NodeManager.\n● Как Kafka обеспечивает «at‑least‑once» доставку сообщений?\n● Зачем использовать bucketing, если уже есть partitioning?\n● Что происходит при потере одного из DataNode в HDFS?\n● Какие гарантии ACID даёт Delta Lake поверх S3?\nРекомендуемые материалы\n● Учебник «Технологии больших данных» (ИТМО)\n● Stepik курс «Большие данные»\n● Документация Apache Spark (рус.)\n7. Основы машинного обучения\nПодтемы\n● Подготовка данных и feature engineering: очистка, обработка пропусков,\nмасштабирование, кодирование категориальных признаков\n● Базовые модели классификации и регрессии: линейные методы, k-NN, Naive\nBayes, решающие деревья\n● Ансамбли и градиентный бустинг (Random Forest, XGBoost, LightGBM, CatBoost)\n● Ядровые методы и метод опорных векторов (SVM)\n● Снижение размерности и визуализация: PCA, LDA, t-SNE, UMAP\n● Оценка качества и предотвращение переобучения: train/val/test-split, k-fold,\nрегуляризация L1/L2, early stopping\n● Метрики сравнения моделей: accuracy, ROC-AUC, PR-AUC, F1, RMSE/MAE, R² и т.д.\n● Подбор гиперпараметров и автоматический поиск: GridSearch,\nRandomizedSearch, Optuna/Bayesian Optimization\n● Интерпретируемость моделей и оценка важности признаков: permutation\nimportance, SHAP\nПримерные вопросы\n● Почему CatBoost не требует one‑hot для категориальных признаков?\n● Сформулируйте задачу SVM в её примале L2‑регуляризованной форме.\n● Как выбрать число компонент PCA, объясняя 95 % дисперсии?\n● В каких случаях t‑SNE лучше UMAP для визуализации?\n● Что показывает площадь под ROC‑кривой (AUC)?\n● Когда целесообразно применять RandomizedSearch вместо GridSearch?\nРекомендуемые материалы\n● Учебник ШАД по ML\n● Курс HSE ML (GitHub)\n● Stepik курс «Машинное обучение»\n● Курс по Машинному обучению Радослава Нейчева и Владислава Гончаренко:\nФИВТ МФТИ. https://github. com/girafe-ai/ml-course\n8. Нейронные сети\nПодтемы\n● Базовые многослойные перцептроны и функции активации\n● Свёрточные сети (CNN) и остаточные блоки (Resnet)\n● НС для обработки последовательностей: RNN, LSTM, GRU, seq2seq с attention\n● Архитектура Transformer: self-attention, позиционные кодировки,\nGPT/BERT-подобные модели\n● Регуляризация и оптимизация: Dropout, Batch/Layer Norm, weight decay,\nAdamW, learning-rate schedules, gradient clipping\n● Early stopping и мониторинг тренировочных/валидационных метрик\n● Перенос обучения и fine-tuning (prompt-, LoRA-, adapters)\n● Генеративные сети: автоэнкодеры и VAE, GAN-семейство (DCGAN, WGAN,\nStyleGAN), diffusion-модели (DDPM, Stable Diffusion)\nПримерные вопросы\n● Чем LSTM отличается от простой RNN с точки зрения градиентов?\n● Опишите механизм multi‑head attention.\n● Как выбрать слои для fine‑tuning при transfer learning?\n● Почему Dropout снижает переобучение?\n● В чём идея циклического learning rate?\n● Какие метрики мониторят для early stopping в задачах классификации?\nРекомендуемые материалы\n● Книга «Нейронные сети и глубокое обучение» (Николенко, pdf)\n● YouTube курс ODS «Нейронные сети»\n● Stepik «Введение в нейронные сети»\n9. Основы компьютерного зрения (CV)\nПодтемы\n● Базовая классификация изображений: CNN-backbone, ResNet, EfficientNet\n● Детекция объектов: YOLO-семейство, SSD, Faster R-CNN, anchor-free подходы\n(CenterNet)\n● Сегментация: U-Net, DeepLab v3+, Mask R-CNN\n● Feature-descriptors и keypoints: SIFT, SURF, ORB, FAST + BRIEF; matching и\nRANSAC\n● Аугментации и инвариантность: flips, crops, color-jitter, CutMix, RandAugment\n● Метрики качества: IoU, mAP@[.5:.95], Dice/F-score, Pixel Accuracy\n● Transfer learning и fine-tuning: фиксированный backbone, freezing, adapters,\nweight decay\n● Современные CV-архитектуры: Vision Transformer (ViT), Swin, ConvNeXt, CLIP и\nmultimodal embeddings\nПримерные вопросы\n● Чем anchor‑based модели отличаются от anchor‑free?\n● Как работает skip‑connection в U‑Net?\n● Почему SIFT устойчив к масштабированию?\n● Назовите три полезных аугментации для малых датасетов.\n● Что означает IoU=0.5 в COCO‑метрике?\n● Как заморозка слоёв помогает при transfer learning?\nРекомендуемые материалы\n● ODS курс «Компьютерное зрение» (YouTube)\n● Stepik «Компьютерное зрение»\n● Документация OpenCV (рус.)\n10. Основы обработки естественного языка (NLP)\nПодтемы\n● Статистические языковые модели: n-gram, сглаживание, перплексия\n● Обучаемые векторные представления: Word2Vec (CBOW/Skip-gram), GloVe,\nFastText\n● Токенизация и субсловные схемы: BPE, SentencePiece, WordPiece, обработка\nOOV\n● Последовательная разметка: CRF, Bi-LSTM-CRF, задачи NER/POS\n● Fine-tuning готовых моделей: BERT/RuBERT, LoRA/PEFT, выбор слоёв для\nзаморозки\n● Основы LLM: causal-LM (GPT-семейство), masked-LM (BERT),\ninstruction-/RLHF-tuning, RAG-подход\n● Оценка качества: BLEU, ROUGE, perplexity, оценка ответов LLM через\nLlama-Guard/Hallucination checks\nПримерные вопросы\n● Что такое сглаживание Кнезера‑Нэя?\n● Опишите обучение Skip‑gram модели Word2Vec.\n● В чём отличие BPE от WordPiece?\n● Какие преимущества CRF над HMM в sequence labeling?\n● Когда BLEU неадекватно оценивает качество перевода?\n● Чем RuBERT отличается от оригинального BERT?\nРекомендуемые материалы\n● NLP курс MIPT (GitHub)\n● Stepik «Введение в NLP»\n● Статья ODS «Разбор BERT на русском»\n11. Инструменты промышленной разработки ПО\nПодтемы\n● Управление версиями и ветвления: Git Flow, trunk-based, semantic versioning,\nRebase vs Merge, Pull-Request workflow\n● Контейнеризация и образы: Dockerfile (best practices, multi-stage build), Docker\nCompose, secrets & env-vars, базовые приёмы оптимизации размера образа\n● Оркестрация и окружения: Kubernetes (Deploy/Service/Ingress), k3d/Minikube для\nлокальной отладки\n● CI/CD конвейеры: GitHub Actions, GitLab CI, автоматические тесты → линтеры →\nbuild → push → deploy, канареечные релизы, rollback-стратегии\n● Тестирование и качество кода: Pytest-fixtures и parametrization,\ncoverage/pytest-cov, linters (ruff/flake8), stat-analysis (Bandit, mypy), contract-тесты\nAPI (pytest-httpx)\n● Мониторинг: Prometheus + Grafana, логирование через Loki/ELK, алерты\nAlertmanager\n● Инфраструктура как код (IaC): Terraform providers (AWS/GCP/Yandex Cloud),\nAnsible roles/playbooks, Molecule-тесты, drift-detection\n● MLOps основы: MLflow / DVC для версионирования моделей и данных\nПримерные вопросы\n● Опишите стратегию GitFlow и её плюсы.\n● Когда следует использовать Docker Compose вместо kubectl apply?\n● Как реализовать многоступенчатый build Docker‑образа?\n● Чем отличатся workflow dispatch от push триггера в GitHub Actions?\n● Какие метрики важно мониторить для REST‑сервиса ML‑модели?\n● Что такое idempotency в Ansible?\nРекомендуемые материалы\n● Книга «Pro Git» (рус.)\n● Документация Docker (рус.)\n● Stepik курс «DevOps практики и инструменты»\n● Документация GitHub Actions (рус.)\n🔗 Пример технического тестирования\nЗадания на написание кода:\nПосле тестовых вопросов с вариантами ответов вам будут предложены 3 задачи\nна написание кода и анализ данных, которые проверяют следующие знания и\nумения:\n1. Программирование на Python\nуверенное владение языком, стандартными библиотеками и системой пакетов.\n2. Обработка данных в табличных форматах\nчтение файлов с табличными данными (Parquet/CSV), группировки,\nагрегирование, вычисление статистик и поиск ответов по данным.\n3. SQL-стиль запросов внутри Python\nумение формулировать выборки и агрегации через pandas / polars / duckdb.\n4. Анализ данных: базовый статистический анализ, визуализация и EDA\nсредние, дисперсия, квантиль, выявление аномалий, подготовка наглядных\nграфиков и формулировка продуктовых гипотез.\n5. Разработка Telegram-/Web-ботов или простейшего UI\nподключение API, организация диалога, обработка пользовательского ввода.\n6. Web-scraping и работа с открытыми источниками\nизвлечение и структурирование данных из HTML-страниц.\n7. Использование LLM как вспомогательного инструмента (RAG)\nпостроение простого retrieval-QA по собственному корпусу документов.\n8. Инженерия, практики DevOps и проектная структура\nчистый репозиторий, README, виртуальное окружение / Docker, тесты, грамотная\nработа с Git, автоматическая проверка и сборка проектов\nКак проверяем?\nРешения таких заданий на написание кода и анализ данных, когда вы\nприкладываете ссылку на решений в своем github-репозитории, будут проходить\nчерез ревью экспертами к собеседованию для оценки вашего умения решать\nсложные задачи в ограниченное время. А на собеседовании будут заданы\nдополнительные вопросы по тому, как вы решали задания с кодом, что было легко,\nа что давалось с трудом.\nПолезные инструменты\n● Язык и среда: Python 3.11+, VS Code / PyCharm + встроенный\nCopilot-chat\n● Обработка и SQL-аналитика: pandas, polars, DuckDB, PyArrow\n● Визуализация и EDA: seaborn, matplotlib, plotly\n● Web-scraping: requests, BeautifulSoup, Playwright\n● Боты, веб-сервисы и REST API: python-telegram-bot / aiogram,\nFastAPI (для REST-эндпоинтов)\n● LLM + Retrieval: OpenAI / YandexGPT SDK, LangChain или llama-index,\nFAISS / Chroma (векторное хранилище)\n● Контроль версий, контейнеры и деплой: Git + Github, Docker,\ndocker-compose, Автоматические проверки и сборка с GitHub\nActions (CI/CD)\n● Тесты и качество кода: pytest, coverage, pre-commit (black, isort,\nflake8)\n● Документация: Jupyter Notebook, Markdown + README templates\nAI Coding Assistant\nВы решаете эти задания в отведенное время технического испытания (вместе с\nтестом у вас всего 4 часа), для ускорения написания кода НЕ запрещается, а\nрекомендуется использовать AI-ассистентов для написания кода, например:\nGitHub Copilot (IDE плагин), Copilot Chat (VS Code), OpenAI GPT-4o в браузере\n(chat.openai.com или API-ключ + curl), Claude Code CLI, Claude 3.5 / 3.7 Sonnet в\nIDE (VS Code, JetBrains), Claude 4 (Opus 4) (chat.claude.ai + API), Cursor (AI IDE на базе\nGPT-4), Codeium (free-плагин для большинства IDE), Yandex GPT / SourceCraft\nCode Assistant и т.д.\nРекомендации по использованию AI Coding Assistant в\nограниченное время\n1. Пишите промпт-задачу целиком («Загрузи Parquet, посчитай 95-квантиль\nпо колонке amount и округли вверх до целого»).\n2. Проверяйте результат сразу: запускайте сэмпл-датасет, ловите ошибки —\nпросите ассистента «почини stack trace».\n3. Оставляйте комментарии: если код сгенерировал ИИ, пометьте кратко, что\nименно он делает — это плюс при ревью.\n4. Просите тесты: «напиши pytest-тест, проверяющий округление вверх».\nАвтотесты экономят нервы на финальной проверке.\n5. Мини-рефактор после генерации: переименуйте переменные, уберите\nлишние импорты — чтобы код был читаем.\nИспользуя AI-помощников, вы сокращаете рутину (парсинг, boilerplate,\nдокументация) и оставляете время на логику решения задачи и проверку\nрезультатов.\nКак тренироваться заранее\n1. Мини-хакатон «1 файл → 8 метрик»\nнайдите любой открытый датасет (например, на Kaggle); поставьте себе 8-10\nвопросов по данным; решите их «вслепую» сначала руками, потом с\nLLM-ассистентом.\n2. «QA-Бот-вечер»:\nвозьмите пару произвольных \\HTML-страниц, спарсите, соберите простейшего\nQA-ассистента в LangChain, поднимите Telegram-бота, который отвечает на\nвопросы по этим данным, попробуйте усложнить обработку интентов, когда в\nодном запросе пользователя может быть более сложная задача, требующая\nприменения уже агентской парадигмы с разными инструментами.\n3. EDA-challenge\nСделайте по любому открытому датасету репо шаблон: notebooks/eda.ipynb, src/,\nrequirements.txt, Makefile test. Пусть LLM сгенерирует draft-README, а вы\nдоведите до ума визуальный анализ данных и предложите ряд продуктовых\nгипотез и инсайтов по данным.\n4. CI/CD за 30 минут\nсклонируйте любой hello-api, подключите GitHub Actions на push: pytest ➜ docker\nbuild ➜ docker push ghcr.io/...",
  "electives": []
}